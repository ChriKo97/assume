{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62e00c9",
   "metadata": {
    "id": "e62e00c9"
   },
   "source": [
    "# **Explainable Reinforcement Learning Tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3aa803",
   "metadata": {
    "id": "fb3aa803"
   },
   "source": [
    "Welcome to this tutorial on **Explainable Reinforcement Learning (XRL)**! In this guide, we'll explore how to interpret and explain the decisions made by reinforcement learning agents using the SHAP (SHapley Additive exPlanations) library. We'll work through a practical example involving an the simulation simulation in a reinforcement learning setting, and demonstrate how to compute and visualize feature attributions for the agent's actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d793362",
   "metadata": {
    "id": "0d793362"
   },
   "source": [
    "**Table of Contents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdf688",
   "metadata": {
    "id": "87bdf688"
   },
   "source": [
    "1. [Introduction](#introduction)\n",
    "\n",
    "    1.1. [Multi-Agent Deep Reinforcement Learning with Market Splitting](#11-multi-agent-deep-reinforcement-learning)\n",
    "\n",
    "2. [Explainable AI and SHAP Values](#2-explainable-ai-and-shap-values)\n",
    "\n",
    "    2.1 Understanding Explainable AI\n",
    "\n",
    "    2.2 Introduction to SHAP Values\n",
    "\n",
    "3. [Calculating SHAP values](#3-calculating-shap-values)\n",
    "\n",
    "    3.1. [Loading and Preparing Data](#loading-and-preparing-data)\n",
    "\n",
    "    3.2. [Creating a SHAP Explainer](#32-creating-a-shap-explainer)\n",
    "    \n",
    "4. [Visualizing SHAP Values](#visualizing-shap-values)\n",
    "5. [Conclusion](#conclusion)\n",
    "6. [Additional Resources](#additional-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c7fec",
   "metadata": {
    "id": "5e8c7fec"
   },
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e91420",
   "metadata": {
    "id": "06e91420"
   },
   "source": [
    "Reinforcement Learning (RL) has achieved remarkable success in various domains, such as game playing, robotics, and autonomous systems. However, RL models, particularly those using deep neural networks, are often seen as black boxes due to their complex architectures and non-linear computations. This opacity poses challenges in understanding and trusting the decisions made by RL agents, especially in critical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b1e7ab",
   "metadata": {
    "id": "47b1e7ab"
   },
   "source": [
    "**Explainable Reinforcement Learning (XRL)** aims to bridge this gap by providing insights into the agent's decision-making process. By leveraging explainability techniques, we can interpret the actions of an RL agent, understand the influence of input features, and potentially improve the model's performance and fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0717c1",
   "metadata": {
    "id": "ec0717c1"
   },
   "source": [
    "In this tutorial, we will demonstrate how to apply SHAP values to a trained actor neural network within an RL framework to explain the agent's actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59bb0a",
   "metadata": {
    "id": "0d59bb0a"
   },
   "source": [
    "### 1.1 Multi-Agent Deep Reinforcement Learning <a name=\"MARL\"></a>\n",
    "\n",
    "In ASSUME, we implement RL agents using a Multi-Agent Deep Reinforcement Learning (MADRL) approach. Key aspects include:\n",
    "\n",
    "\n",
    "- **Observations**: Each agent receives observations comprising market forecasts, unit-specific information, and past actions.\n",
    "- **Actions**: Agents decide on bidding strategies, such as bid prices for inflexible and flexible capacities.\n",
    "- **Rewards**: Agents receive rewards based on profits and opportunity costs, guiding them to learn optimal bidding strategies.\n",
    "- **Algorithm**: We utilize a multi-agent version of the TD3 algorithm, ensuring stable learning in a non-stationary environment.\n",
    "\n",
    "For a deep dive into the RL configurations we refer to one of the other tutorials, such as\n",
    "[Deep Reinforcement Learning Tutorial](https://example.com/deep-rl-tutorial)\n",
    "\n",
    "Agents need observations to make informed decisions. Observations include:\n",
    "\n",
    "- **Residual Load Forecast**: Forecasted net demand over the next 24 hours.\n",
    "- **Price Forecast**: Forecasted market prices over the next 24 hours.\n",
    "- **Marginal Cost**: Current marginal cost of the unit.\n",
    "- **Previous Output**: Dispatched capacity from the previous time step.\n",
    "\n",
    "\n",
    "Agents choose actions based on the observations. The action space is two-dimensional, corresponding to:\n",
    "\n",
    "- Bid Price for Inflexible Capacity (p_inflex): The price at which the agent offers its minimum power output (must-run capacity) to the market.\n",
    "- Bid Price for Flexible Capacity (p_flex): The price for the additional capacity above the minimum output that the agent can flexibly adjust.\n",
    "\n",
    "\n",
    "#### Run an the simulation MADRL Simulation\n",
    "\n",
    "Similar to the other tutorial, we can run Assume in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee220130",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ee220130",
    "outputId": "ffd98b47-2b07-41cd-dfe4-ff0381571825",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install 'assume-framework[learning]'\n",
    "#!pip install plotly\n",
    "#!git clone https://github.com/assume-framework/assume.git assume-repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Hn_DvrqR7oK2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hn_DvrqR7oK2",
    "outputId": "391046fd-90d9-4967-b919-52c49f13a9f8",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbconvert\n",
      "  Using cached nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert)\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbconvert) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbconvert) (5.7.2)\n",
      "Collecting jupyterlab-pygments (from nbconvert)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbconvert) (2.1.5)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert)\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert)\n",
      "  Using cached nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbconvert) (5.10.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbconvert) (24.1)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert)\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbconvert) (2.18.0)\n",
      "Collecting tinycss2 (from nbconvert)\n",
      "  Using cached tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbconvert) (5.14.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (306)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbclient>=0.5.0->nbconvert) (8.6.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbformat>=5.7->nbconvert) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\tg3533\\appdata\\local\\miniconda3\\envs\\assume-framework\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.4.1)\n",
      "Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Using cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Using cached nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, tinycss2, soupsieve, pandocfilters, mistune, jupyterlab-pygments, defusedxml, bleach, beautifulsoup4, nbclient, nbconvert\n",
      "Successfully installed beautifulsoup4-4.12.3 bleach-6.1.0 defusedxml-0.7.1 jupyterlab-pygments-0.3.0 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.4 pandocfilters-1.5.1 soupsieve-2.6 tinycss2-1.3.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyomo\n",
    "#!apt-get install -y -qq glpk-utils\n",
    "!pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cd480a",
   "metadata": {
    "id": "75cd480a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import plotly for visualization\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# import yaml for reading and writing YAML files\n",
    "import yaml\n",
    "\n",
    "# Function to display DataFrame in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd1daf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfd1daf2",
    "outputId": "1edeb31f-bc3a-493e-b518-01f4188c44b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../inputs\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "\n",
    "# Check if 'google.colab' is available\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "colab_inputs_path = \"assume-repo/examples/inputs\"\n",
    "local_inputs_path = \"../inputs\"\n",
    "\n",
    "inputs_path = colab_inputs_path if IN_COLAB else local_inputs_path\n",
    "\n",
    "print(inputs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ea9ae",
   "metadata": {
    "id": "636ea9ae"
   },
   "source": [
    "Load the created example files from the tutorial before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988d3e15",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] Das System kann die angegebene Datei nicht finden: 'content'\n",
      "c:\\Users\\tg3533\\Documents\\Code\\assume\\examples\\notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 08_market_zone_coupling.ipynb to notebook\n",
      "C:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\zmq\\_future.py:724: RuntimeWarning: Proactor event loop does not implement add_reader family of methods required for zmq. Registering an additional selector thread for add_reader support via tornado. Use `asyncio.set_event_loop_policy(WindowsSelectorEventLoopPolicy())` to avoid this warning.\n",
      "  self._get_loop()\n",
      "[NbConvertApp] Writing 188324 bytes to output.ipynb\n",
      "Der Befehl \"cp\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "#if used locally\n",
    "#%cd assume/examples/notebooks/\n",
    "\n",
    "# if used in colab\n",
    "#%cd assume-repo/examples/notebooks/\n",
    "\n",
    "#!jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=60 --output output.ipynb 08_market_zone_coupling.ipynb\n",
    " \n",
    "#%cd content\n",
    "#!cp -r assume-repo/examples/notebooks/inputs ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233f315b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "233f315b",
    "outputId": "f98da7d4-0080-4546-c642-838f722965b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input CSV files have been read from 'inputs/tutorial_08'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the input directory\n",
    "input_dir = os.path.join(inputs_path, \"tutorial_08\")\n",
    "\n",
    "\n",
    "# Read the DataFrames from CSV files\n",
    "buses = pd.read_csv(os.path.join(input_dir, \"buses.csv\"))\n",
    "lines = pd.read_csv(os.path.join(input_dir, \"lines.csv\"))\n",
    "powerplant_units = pd.read_csv(os.path.join(input_dir, \"powerplant_units.csv\"))\n",
    "demand_units = pd.read_csv(os.path.join(input_dir, \"demand_units.csv\"))\n",
    "demand_df = pd.read_csv(os.path.join(input_dir, \"demand_df.csv\"))\n",
    "\n",
    "# extend demand_df for another day with the same demand profile\n",
    "demand_df = pd.concat([demand_df, demand_df])\n",
    "demand_df.index = pd.date_range(start=\"2019-01-01\", periods=96, freq=\"h\")\n",
    "\n",
    "# Read the fuel prices DataFrame from CSV file\n",
    "fuel_prices_df = pd.read_csv(os.path.join(input_dir, \"fuel_prices_df.csv\"))\n",
    "\n",
    "\n",
    "print(\"Input CSV files have been read from 'inputs/tutorial_08'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985289b",
   "metadata": {
    "id": "6985289b"
   },
   "source": [
    "**Let's make this a leanring example**\n",
    "\n",
    "We place a learning nuclear power plant in the south zone that has a 5 times hihger maximal power, to generate a scenario where it has a price impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b205256f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "b205256f",
    "outputId": "b9bb887b-f534-4a50-dd5b-229be1012600"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>technology</th>\n",
       "      <th>bidding_zonal</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>emission_factor</th>\n",
       "      <th>max_power</th>\n",
       "      <th>min_power</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>additional_cost</th>\n",
       "      <th>node</th>\n",
       "      <th>unit_operator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unit 1</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Unit 2</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Unit 3</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Unit 4</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Unit 5</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Unit 6</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Unit 7</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Unit 8</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12</td>\n",
       "      <td>north_1</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Unit 9</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13</td>\n",
       "      <td>north_2</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Unit 10</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14</td>\n",
       "      <td>north_2</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Unit 11</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>north_2</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Unit 12</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16</td>\n",
       "      <td>north_2</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Unit 13</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>north_2</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>Unit 14</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>north_2</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Unit 15</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19</td>\n",
       "      <td>north_2</td>\n",
       "      <td>Operator North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Unit 16</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>south</td>\n",
       "      <td>Operator South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>Unit 17</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21</td>\n",
       "      <td>south</td>\n",
       "      <td>Operator South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Unit 18</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22</td>\n",
       "      <td>south</td>\n",
       "      <td>Operator South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>Unit 19</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>naive_eom</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23</td>\n",
       "      <td>south</td>\n",
       "      <td>Operator South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Unit 20</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>pp_learning</td>\n",
       "      <td>uranium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24</td>\n",
       "      <td>south</td>\n",
       "      <td>Operator-RL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0     name technology  \\\n",
       "0              0             0             0           0   Unit 1    nuclear   \n",
       "1              1             1             1           1   Unit 2    nuclear   \n",
       "2              2             2             2           2   Unit 3    nuclear   \n",
       "3              3             3             3           3   Unit 4    nuclear   \n",
       "4              4             4             4           4   Unit 5    nuclear   \n",
       "5              5             5             5           5   Unit 6    nuclear   \n",
       "6              6             6             6           6   Unit 7    nuclear   \n",
       "7              7             7             7           7   Unit 8    nuclear   \n",
       "8              8             8             8           8   Unit 9    nuclear   \n",
       "9              9             9             9           9  Unit 10    nuclear   \n",
       "10            10            10            10          10  Unit 11    nuclear   \n",
       "11            11            11            11          11  Unit 12    nuclear   \n",
       "12            12            12            12          12  Unit 13    nuclear   \n",
       "13            13            13            13          13  Unit 14    nuclear   \n",
       "14            14            14            14          14  Unit 15    nuclear   \n",
       "15            15            15            15          15  Unit 16    nuclear   \n",
       "16            16            16            16          16  Unit 17    nuclear   \n",
       "17            17            17            17          17  Unit 18    nuclear   \n",
       "18            18            18            18          18  Unit 19    nuclear   \n",
       "19            19            19            19          19  Unit 20    nuclear   \n",
       "\n",
       "   bidding_zonal fuel_type  emission_factor  max_power  min_power  efficiency  \\\n",
       "0      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "1      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "2      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "3      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "4      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "5      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "6      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "7      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "8      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "9      naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "10     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "11     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "12     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "13     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "14     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "15     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "16     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "17     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "18     naive_eom   uranium              0.0     1000.0        0.0         0.3   \n",
       "19   pp_learning   uranium              0.0     5000.0        0.0         0.3   \n",
       "\n",
       "    additional_cost     node   unit_operator  \n",
       "0                 5  north_1  Operator North  \n",
       "1                 6  north_1  Operator North  \n",
       "2                 7  north_1  Operator North  \n",
       "3                 8  north_1  Operator North  \n",
       "4                 9  north_1  Operator North  \n",
       "5                10  north_1  Operator North  \n",
       "6                11  north_1  Operator North  \n",
       "7                12  north_1  Operator North  \n",
       "8                13  north_2  Operator North  \n",
       "9                14  north_2  Operator North  \n",
       "10               15  north_2  Operator North  \n",
       "11               16  north_2  Operator North  \n",
       "12               17  north_2  Operator North  \n",
       "13               18  north_2  Operator North  \n",
       "14               19  north_2  Operator North  \n",
       "15               20    south  Operator South  \n",
       "16               21    south  Operator South  \n",
       "17               22    south  Operator South  \n",
       "18               23    south  Operator South  \n",
       "19               24    south     Operator-RL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create scarcity in south germany\n",
    "powerplant_units = powerplant_units[:20]\n",
    "\n",
    "# assign RL power plant and give it market power\n",
    "powerplant_units.loc[19, \"bidding_zonal\"] = \"pp_learning\"\n",
    "powerplant_units.loc[19, \"max_power\"] = 5000\n",
    "\n",
    "# assig specific RL unit operator to plant\n",
    "powerplant_units.loc[19, \"unit_operator\"] = \"Operator-RL\"\n",
    "\n",
    "powerplant_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "QBTGrw62_5I7",
   "metadata": {
    "id": "QBTGrw62_5I7"
   },
   "outputs": [],
   "source": [
    "# store power plant units to csv again\n",
    "powerplant_units.to_csv(input_dir + \"/powerplant_units.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0e8b4",
   "metadata": {
    "id": "cce0e8b4"
   },
   "source": [
    "Change the yaml to configure the learning specific hyperparameters. For a deep dive explanation of the different parameters we refer again to the solely RL tutorial. **TODO** Erklärung einfügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c555ce9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c555ce9",
    "outputId": "473126ae-3c3e-4698-e3a5-347cc00e5108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration YAML file has been saved to '../inputs\\tutorial_08\\config.yaml'.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"zonal_case\": {\n",
    "        \"start_date\": \"2019-01-01 00:00\",\n",
    "        \"end_date\": \"2019-01-01 23:00\",\n",
    "        \"time_step\": \"1h\",\n",
    "        \"save_frequency_hours\": 24,\n",
    "        \"learning_mode\": \"True\",\n",
    "        \"markets_config\": {\n",
    "            \"zonal\": {\n",
    "                \"operator\": \"EOM_operator\",\n",
    "                \"product_type\": \"energy\",\n",
    "                \"products\": [{\"duration\": \"1h\", \"count\": 1, \"first_delivery\": \"1h\"}],\n",
    "                \"opening_frequency\": \"1h\",\n",
    "                \"opening_duration\": \"1h\",\n",
    "                \"volume_unit\": \"MWh\",\n",
    "                \"maximum_bid_volume\": 100000,\n",
    "                \"maximum_bid_price\": 3000,\n",
    "                \"minimum_bid_price\": -500,\n",
    "                \"price_unit\": \"EUR/MWh\",\n",
    "                \"market_mechanism\": \"pay_as_clear_complex\",\n",
    "                \"additional_fields\": [\"bid_type\", \"node\"],\n",
    "                \"param_dict\": {\"network_path\": \".\", \"zones_identifier\": \"zone_id\"},\n",
    "            }\n",
    "        },\n",
    "        \"learning_config\": {\n",
    "            \"continue_learning\": False,\n",
    "            \"trained_policies_save_path\": \"null\",\n",
    "            \"max_bid_price\": 100,\n",
    "            \"algorithm\": \"matd3\",\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"training_episodes\": 10,\n",
    "            \"episodes_collecting_initial_experience\": 3,\n",
    "            \"train_freq\": \"24h\",\n",
    "            \"gradient_steps\": -1,\n",
    "            \"batch_size\": 256,\n",
    "            \"gamma\": 0.99,\n",
    "            \"device\": \"cpu\",\n",
    "            \"noise_sigma\": 0.1,\n",
    "            \"noise_scale\": 1,\n",
    "            \"noise_dt\": 1,\n",
    "            \"validation_episodes_interval\": 5,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the path for the config file\n",
    "config_path = os.path.join(input_dir, \"config.yaml\")\n",
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config, file, sort_keys=False)\n",
    "\n",
    "print(f\"Configuration YAML file has been saved to '{config_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f38fb",
   "metadata": {
    "id": "3f0f38fb"
   },
   "source": [
    "For XRL, we need enhanced logging of the learning process, which is not currently a feature of ASSUME itself. Therefore, we are overriding some functions to enable this logging specifically for the purpose of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201251c6",
   "metadata": {
    "cellView": "form",
    "id": "201251c6"
   },
   "outputs": [],
   "source": [
    "# @title Overwrite run_learning function with enhanced logging\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from assume.common.exceptions import AssumeException\n",
    "from assume.scenario.loader_csv import (\n",
    "    load_config_and_create_forecaster,\n",
    "    setup_world,\n",
    ")\n",
    "from assume.world import World\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def run_learning(\n",
    "    world: World,\n",
    "    inputs_path: str,\n",
    "    scenario: str,\n",
    "    study_case: str,\n",
    "    verbose: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train Deep Reinforcement Learning (DRL) agents to act in a simulated market environment.\n",
    "\n",
    "    This function runs multiple episodes of simulation to train DRL agents, performs evaluation, and saves the best runs. It maintains the buffer and learned agents in memory to avoid resetting them with each new run.\n",
    "\n",
    "    Args:\n",
    "        world (World): An instance of the World class representing the simulation environment.\n",
    "        inputs_path (str): The path to the folder containing input files necessary for the simulation.\n",
    "        scenario (str): The name of the scenario for the simulation.\n",
    "        study_case (str): The specific study case for the simulation.\n",
    "\n",
    "    Note:\n",
    "        - The function uses a ReplayBuffer to store experiences for training the DRL agents.\n",
    "        - It iterates through training episodes, updating the agents and evaluating their performance at regular intervals.\n",
    "        - Initial exploration is active at the beginning and is disabled after a certain number of episodes to improve the performance of DRL algorithms.\n",
    "        - Upon completion of training, the function performs an evaluation run using the best policy learned during training.\n",
    "        - The best policies are chosen based on the average reward obtained during the evaluation runs, and they are saved for future use.\n",
    "    \"\"\"\n",
    "    from assume.reinforcement_learning.buffer import ReplayBuffer\n",
    "\n",
    "    if not verbose:\n",
    "        logger.setLevel(logging.WARNING)\n",
    "\n",
    "    # remove csv path so that nothing is written while learning\n",
    "    temp_csv_path = world.export_csv_path\n",
    "    world.export_csv_path = \"\"\n",
    "\n",
    "    # initialize policies already here to set the obs_dim and act_dim in the learning role\n",
    "    actors_and_critics = None\n",
    "    world.learning_role.initialize_policy(actors_and_critics=actors_and_critics)\n",
    "    world.output_role.del_similar_runs()\n",
    "\n",
    "    # check if we already stored policies for this simualtion\n",
    "    save_path = world.learning_config[\"trained_policies_save_path\"]\n",
    "\n",
    "    if Path(save_path).is_dir():\n",
    "        # we are in learning mode and about to train new policies, which might overwrite existing ones\n",
    "        accept = input(\n",
    "            f\"{save_path=} exists - should we overwrite current learnings? (y/N) \"\n",
    "        )\n",
    "        if not accept.lower().startswith(\"y\"):\n",
    "            # stop here - do not start learning or save anything\n",
    "            raise AssumeException(\"don't overwrite existing strategies\")\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Load scenario data to reuse across episodes\n",
    "    scenario_data = load_config_and_create_forecaster(inputs_path, scenario, study_case)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Information that needs to be stored across episodes, aka one simulation run\n",
    "    inter_episodic_data = {\n",
    "        \"buffer\": ReplayBuffer(\n",
    "            buffer_size=int(world.learning_config.get(\"replay_buffer_size\", 5e5)),\n",
    "            obs_dim=world.learning_role.rl_algorithm.obs_dim,\n",
    "            act_dim=world.learning_role.rl_algorithm.act_dim,\n",
    "            n_rl_units=len(world.learning_role.rl_strats),\n",
    "            device=world.learning_role.device,\n",
    "            float_type=world.learning_role.float_type,\n",
    "        ),\n",
    "        \"actors_and_critics\": None,\n",
    "        \"max_eval\": defaultdict(lambda: -1e9),\n",
    "        \"all_eval\": defaultdict(list),\n",
    "        \"avg_all_eval\": [],\n",
    "        \"episodes_done\": 0,\n",
    "        \"eval_episodes_done\": 0,\n",
    "        \"noise_scale\": world.learning_config.get(\"noise_scale\", 1.0),\n",
    "    }\n",
    "\n",
    "    # -----------------------------------------\n",
    "\n",
    "    validation_interval = min(\n",
    "        world.learning_role.training_episodes,\n",
    "        world.learning_config.get(\"validation_episodes_interval\", 5),\n",
    "    )\n",
    "\n",
    "    eval_episode = 1\n",
    "\n",
    "    for episode in tqdm(\n",
    "        range(1, world.learning_role.training_episodes + 1),\n",
    "        desc=\"Training Episodes\",\n",
    "    ):\n",
    "        # TODO normally, loading twice should not create issues, somehow a scheduling issue is raised currently\n",
    "        if episode != 1:\n",
    "            setup_world(\n",
    "                world=world,\n",
    "                scenario_data=scenario_data,\n",
    "                study_case=study_case,\n",
    "                episode=episode,\n",
    "            )\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # Give the newly initliazed learning role the needed information across episodes\n",
    "        world.learning_role.load_inter_episodic_data(inter_episodic_data)\n",
    "\n",
    "        world.run()\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # Store updated information across episodes\n",
    "        inter_episodic_data = world.learning_role.get_inter_episodic_data()\n",
    "        inter_episodic_data[\"episodes_done\"] = episode\n",
    "\n",
    "        # evaluation run:\n",
    "        if (\n",
    "            episode % validation_interval == 0\n",
    "            and episode\n",
    "            >= world.learning_role.episodes_collecting_initial_experience\n",
    "            + validation_interval\n",
    "        ):\n",
    "            world.reset()\n",
    "\n",
    "            # load evaluation run\n",
    "            setup_world(\n",
    "                world=world,\n",
    "                scenario_data=scenario_data,\n",
    "                study_case=study_case,\n",
    "                perform_evaluation=True,\n",
    "                eval_episode=eval_episode,\n",
    "            )\n",
    "\n",
    "            world.learning_role.load_inter_episodic_data(inter_episodic_data)\n",
    "\n",
    "            world.run()\n",
    "\n",
    "            total_rewards = world.output_role.get_sum_reward()\n",
    "            avg_reward = np.mean(total_rewards)\n",
    "            # check reward improvement in evaluation run\n",
    "            # and store best run in eval folder\n",
    "            terminate = world.learning_role.compare_and_save_policies(\n",
    "                {\"avg_reward\": avg_reward}\n",
    "            )\n",
    "\n",
    "            inter_episodic_data[\"eval_episodes_done\"] = eval_episode\n",
    "\n",
    "            # if we have not improved in the last x evaluations, we stop loop\n",
    "            if terminate:\n",
    "                break\n",
    "\n",
    "            eval_episode += 1\n",
    "\n",
    "        world.reset()\n",
    "\n",
    "        # if at end of simulation save last policies\n",
    "        if episode == (world.learning_role.training_episodes):\n",
    "            world.learning_role.rl_algorithm.save_params(\n",
    "                directory=f\"{world.learning_role.trained_policies_save_path}/last_policies\"\n",
    "            )\n",
    "\n",
    "            # export buffer_obs.json in the last training episode to get observations later\n",
    "            export = inter_episodic_data[\"buffer\"].observations.tolist()\n",
    "            path = f\"{world.learning_role.trained_policies_save_path}/buffer_obs\"\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            with open(os.path.join(path, \"buffer_obs.json\"), \"w\") as f:\n",
    "                json.dump(export, f)\n",
    "\n",
    "        # container shutdown implicitly with new initialisation\n",
    "    logger.info(\"################\")\n",
    "    logger.info(\"Training finished, Start evaluation run\")\n",
    "    world.export_csv_path = temp_csv_path\n",
    "\n",
    "    world.reset()\n",
    "\n",
    "    # load scenario for evaluation\n",
    "    setup_world(\n",
    "        world=world,\n",
    "        scenario_data=scenario_data,\n",
    "        study_case=study_case,\n",
    "        terminate_learning=True,\n",
    "    )\n",
    "\n",
    "    world.learning_role.load_inter_episodic_data(inter_episodic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcacfe26",
   "metadata": {
    "id": "dcacfe26"
   },
   "source": [
    "**Run the example case**\n",
    "\n",
    "Now we run the example case similar to before in the market zone tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfadf522",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bfadf522",
    "outputId": "7c91ab13-a3c2-4e89-d8ac-d20be95391f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:connected to db\n",
      "INFO:assume.scenario.loader_csv:Starting Scenario tutorial_08/zonal_case from ../inputs\n",
      "INFO:assume.scenario.loader_csv:storage_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:industrial_dsm_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:forecasts_df not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:cross_border_flows not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:availability_df not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:electricity_prices not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:price_forecasts not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:temperature not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:Adding markets\n",
      "INFO:assume.scenario.loader_csv:Read units from file\n",
      "INFO:assume.scenario.loader_csv:Adding power_plant units\n",
      "INFO:assume.scenario.loader_csv:Adding demand units\n",
      "INFO:assume.scenario.loader_csv:Adding unit operators and units\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/82800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.common.outputs:tried writing grid data to non postGIS database\n",
      "ERROR:mango.agent.core:The check inbox task of Operator South failed!\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\core.py\", line 450, in _check_inbox\n",
      "    self.handle_message(content=content, meta=meta)\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\role.py\", line 525, in handle_message\n",
      "    self._role_context.handle_message(content, meta)\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\role.py\", line 401, in handle_message\n",
      "    self._role_handler.handle_message(content, meta)\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\role.py\", line 239, in handle_message\n",
      "    method(content, meta)\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\units_operator.py\", line 211, in handle_market_feedback\n",
      "    self.write_actual_dispatch(marketconfig.product_type)\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\units_operator.py\", line 348, in write_actual_dispatch\n",
      "    market_dispatch, unit_dispatch_dfs = self.get_actual_dispatch(\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\units_operator.py\", line 306, in get_actual_dispatch\n",
      "    market_dispatch = aggregate_step_amount(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\utils.py\", line 315, in aggregate_step_amount\n",
      "    groupdata_str = \"_\".join(groupdata)\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 1: expected str instance, int found\n",
      "ERROR:mango.agent.core:The check inbox task of Operator North failed!\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\core.py\", line 450, in _check_inbox\n",
      "    self.handle_message(content=content, meta=meta)\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\role.py\", line 525, in handle_message\n",
      "    self._role_context.handle_message(content, meta)\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\role.py\", line 401, in handle_message\n",
      "    self._role_handler.handle_message(content, meta)\n",
      "  File \"c:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\mango\\agent\\role.py\", line 239, in handle_message\n",
      "    method(content, meta)\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\units_operator.py\", line 211, in handle_market_feedback\n",
      "    self.write_actual_dispatch(marketconfig.product_type)\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\units_operator.py\", line 348, in write_actual_dispatch\n",
      "    market_dispatch, unit_dispatch_dfs = self.get_actual_dispatch(\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\units_operator.py\", line 306, in get_actual_dispatch\n",
      "    market_dispatch = aggregate_step_amount(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tg3533\\Documents\\Code\\assume\\assume\\common\\utils.py\", line 315, in aggregate_step_amount\n",
      "    groupdata_str = \"_\".join(groupdata)\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 1: expected str instance, int found\n"
     ]
    }
   ],
   "source": [
    "# import the main World class and the load_scenario_folder functions from assume\n",
    "from assume import World\n",
    "from assume.scenario.loader_csv import load_scenario_folder\n",
    "\n",
    "# Define paths for input and output data\n",
    "csv_path = \"outputs\"\n",
    "\n",
    "# Define the data format and database URI\n",
    "# Use \"local_db\" for SQLite database or \"timescale\" for TimescaleDB in Docker\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(csv_path, exist_ok=True)\n",
    "os.makedirs(\"local_db\", exist_ok=True)\n",
    "\n",
    "data_format = \"local_db\"  # \"local_db\" or \"timescale\"\n",
    "\n",
    "if data_format == \"local_db\":\n",
    "    db_uri = \"sqlite:///local_db/assume_db.db\"\n",
    "elif data_format == \"timescale\":\n",
    "    db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "\n",
    "# Create the World instance\n",
    "world = World(database_uri=db_uri, export_csv_path=csv_path)\n",
    "\n",
    "# Load the scenario by providing the world instance\n",
    "# The path to the inputs folder and the scenario name (subfolder in inputs)\n",
    "# and the study case name (which config to use for the simulation)\n",
    "load_scenario_folder(\n",
    "    world,\n",
    "    inputs_path=inputs_path,\n",
    "    scenario=\"tutorial_08\",\n",
    "    study_case=\"zonal_case\",\n",
    ")\n",
    "\n",
    "# run learning if learning mode is enabled\n",
    "# needed as we simulate the modelling horizon multiple times to train reinforcement learning run_learning( world, inputs_path=input_path, scenario=scenario, study_case=study_case, )\n",
    "\n",
    "if world.learning_config.get(\"learning_mode\", False):\n",
    "    run_learning(\n",
    "        world,\n",
    "        inputs_path=inputs_path,\n",
    "        scenario=\"tutorial_08\",\n",
    "        study_case=\"zonal_case\",\n",
    "    )\n",
    "\n",
    "# Run the simulation\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "DhYXvzaP_iyK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhYXvzaP_iyK",
    "outputId": "73259557-0218-42da-ec23-ab7a9713ed54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.learning_config.get(\"learning_mode\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194f71b",
   "metadata": {
    "id": "2194f71b"
   },
   "source": [
    "**Generate same plotly figure**\n",
    "\n",
    "We use the same code described in the amarket zone tutprial to generate the plotly curve displaying the market price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb21cbe",
   "metadata": {
    "id": "bdb21cbe"
   },
   "outputs": [],
   "source": [
    "# @ title make makret price plotly figure\n",
    "\n",
    "\n",
    "# Define the path to the simulation output\n",
    "output_dir = \"outputs/tutorial_08_zonal_case\"\n",
    "market_meta_path = os.path.join(output_dir, \"market_meta.csv\")\n",
    "\n",
    "# Load the market_meta.csv file\n",
    "market_meta = pd.read_csv(market_meta_path, index_col=\"time\", parse_dates=True)\n",
    "# drop the first column\n",
    "market_meta = market_meta.drop(columns=market_meta.columns[0])\n",
    "\n",
    "\n",
    "# Extract unique zones\n",
    "zones = market_meta[\"node\"].unique()\n",
    "\n",
    "# Initialize an empty DataFrame to store clearing prices per zone and time\n",
    "clearing_prices_df = pd.DataFrame()\n",
    "\n",
    "# Populate the DataFrame with clearing prices for each zone\n",
    "for zone in zones:\n",
    "    zone_data = market_meta[market_meta[\"node\"] == zone][[\"price\"]]\n",
    "    zone_data = zone_data.rename(columns={\"price\": f\"{zone}_price\"})\n",
    "    clearing_prices_df = (\n",
    "        pd.merge(\n",
    "            clearing_prices_df,\n",
    "            zone_data,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"outer\",\n",
    "        )\n",
    "        if not clearing_prices_df.empty\n",
    "        else zone_data\n",
    "    )\n",
    "\n",
    "# Sort the DataFrame by time\n",
    "clearing_prices_df = clearing_prices_df.sort_index()\n",
    "\n",
    "\n",
    "# Initialize the Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each zone to plot clearing prices\n",
    "for zone in zones:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=clearing_prices_df.index,\n",
    "            y=clearing_prices_df[f\"{zone}_price\"],\n",
    "            mode=\"lines\",\n",
    "            name=f\"{zone} - Simulation\",\n",
    "            line=dict(width=2),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Update layout for better aesthetics and interactivity\n",
    "fig.update_layout(\n",
    "    title=\"Clearing Prices per Zone Over Time: Simulation Results\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Clearing Price (EUR/MWh)\",\n",
    "    legend_title=\"Market Zones\",\n",
    "    xaxis=dict(\n",
    "        tickangle=45,\n",
    "        type=\"date\",  # Ensure the x-axis is treated as dates\n",
    "    ),\n",
    "    hovermode=\"x unified\",  # Unified hover for better comparison\n",
    "    template=\"plotly_white\",  # Clean white background\n",
    "    width=1000,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# Display the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c41cf",
   "metadata": {
    "id": "e77c41cf"
   },
   "source": [
    "## 2. Explainable AI and SHAP Values <a name=\"explainable-ai-and-shap-values\"></a>\n",
    "\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf18570",
   "metadata": {
    "id": "cbf18570"
   },
   "source": [
    "To follow along with this tutorial, we need some additional libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac592c",
   "metadata": {
    "id": "a5ac592c"
   },
   "source": [
    "- `matplotlib`\n",
    "- `shap`\n",
    "- `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae266ecb",
   "metadata": {
    "id": "ae266ecb",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install shap==0.42.1\n",
    "!pip install scikit-learn==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5069ff93",
   "metadata": {
    "id": "5069ff93"
   },
   "source": [
    "### 2.1 Understanding Explainable AI\n",
    "Explainable AI (XAI) refers to techniques and methods that make the behavior and decisions of AI systems understandable to humans. In the context of complex models like deep neural networks, XAI helps to:\n",
    "- Increase Transparency: Providing insights into how models make decisions.\n",
    "- Build Trust: Users and stakeholders can trust AI systems if they understand them.\n",
    "- Ensure Compliance: Regulatory requirements often demand explainability.\n",
    "- Improve Models: Identifying weaknesses or biases in models.\n",
    "\n",
    "\n",
    "### 2.2 Introduction to SHAP Values\n",
    "Shapley values are a method from cooperative game theory used to explain the contribution of each feature to the prediction of a machine learning model, such as a neural network. They provide an interpretability technique by distributing the \"payout\" (the prediction) among the input features, attributing the importance of each feature to the prediction.\n",
    "\n",
    "For a given prediction, the Shapley value of a feature represents the average contribution of that feature to the prediction, considering all possible combinations of other features.\n",
    "\n",
    "1. **Marginal Contribution**:\n",
    "   The marginal contribution of a feature is the difference between the prediction with and without that feature.\n",
    "\n",
    "2. **Average over all subsets**:\n",
    "   The Shapley value is calculated by averaging the marginal contributions over all possible subsets of features.\n",
    "\n",
    "The formula for the Shapley value of feature $i$ is:\n",
    "\n",
    "$$\n",
    "\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!(|N| - |S| - 1)!}{|N|!} \\cdot \\left( f(S \\cup \\{i\\}) - f(S) \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ is the set of all features.\n",
    "- $S$ is a subset of features.\n",
    "- $f(S)$ is the model’s prediction when using only the features in subset $S$.\n",
    "\n",
    "\n",
    "The `shap` library is a popular tool for computing Shapley values for machine learning models, including neural networks.\n",
    "\n",
    "\n",
    "\n",
    "Why Use SHAP in RL?\n",
    "- Model-Agnostic: Applicable to any machine learning model, including neural networks.\n",
    "- Local Explanations: Provides explanations for individual predictions (actions).\n",
    "- Consistency: Ensures that features contributing more to the prediction have higher Shapley values.\n",
    "\n",
    "\n",
    "Properties of SHAP:\n",
    "1. Local Accuracy: The sum of Shapley values equals the difference between the model output and the expected output.\n",
    "2. Missingness: Features not present in the model have zero Shapley value.\n",
    "3. Consistency: If a model changes so that a feature contributes more to the prediction, the Shapley value of that feature should not decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d49573",
   "metadata": {
    "id": "21d49573"
   },
   "source": [
    "## 3. Calculating SHAP values <a name=\"calculating-shap-values\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16712fc",
   "metadata": {
    "id": "d16712fc"
   },
   "source": [
    "We will work with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c1262",
   "metadata": {
    "id": "2c0c1262"
   },
   "source": [
    "- **Observations (`input_data`)**: These are the inputs to our actor neural network, representing the state of the environment.\n",
    "- **Trained Actor Model**: A neural network representing the decision making of one RL power plant that outputs actions based on the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb6fc14",
   "metadata": {
    "id": "2fb6fc14"
   },
   "source": [
    "Our goal is to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b69db6",
   "metadata": {
    "id": "e0b69db6"
   },
   "source": [
    "- Load the observations and the trained actor model.\n",
    "- Use the model to predict actions.\n",
    "- Apply SHAP to explain the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870b3e8",
   "metadata": {
    "id": "f870b3e8"
   },
   "source": [
    "### 3.1. Loading and Preparing Data <a name=\"loading-and-preparing-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7c3d3",
   "metadata": {
    "id": "aaa7c3d3"
   },
   "source": [
    "First, let's load the necessary libraries and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee4f28",
   "metadata": {
    "id": "b6ee4f28"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shap\n",
    "import torch as th\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa268f14",
   "metadata": {
    "id": "aa268f14"
   },
   "source": [
    "the simulation common.py contains utility functions and class definitions\n",
    "from common import load_observations, Actor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866385a",
   "metadata": {
    "id": "f866385a"
   },
   "source": [
    "**Define the Actor Neural Network Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7cf03a",
   "metadata": {
    "id": "ff7cf03a"
   },
   "source": [
    "We define the actor neural network class that will be used to predict actions based on observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216677a",
   "metadata": {
    "id": "7216677a",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from assume.reinforcement_learning.neural_network_architecture import MLPActor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d6e17",
   "metadata": {
    "id": "5a4d6e17"
   },
   "outputs": [],
   "source": [
    "def load_config(file_path):\n",
    "    \"\"\"\n",
    "    Load the configuration file.\n",
    "    \"\"\"\n",
    "    with open(file_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "\n",
    "# Some Variable definitions:\n",
    "\n",
    "EPISODES = 3\n",
    "NUMBER_OF_AGENTS = 1\n",
    "SIM_TIMESPAN_DAYS = 31\n",
    "ACTOR_NUM = 1\n",
    "EXAMPLE = 1\n",
    "\n",
    "SIM_TIMESPAN_HOURS = SIM_TIMESPAN_DAYS * 24\n",
    "\n",
    "# actor 1-5 are the default non-rl actors, so we just skip those\n",
    "ACTOR_NUM_ADJ = ACTOR_NUM + 6  # 6 #9\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Go up one level\n",
    "one_level_up = os.path.dirname(current_dir)\n",
    "# Go up two levels\n",
    "two_levels_up = os.path.dirname(one_level_up)\n",
    "\n",
    "# Paths\n",
    "path = os.path.join(\n",
    "    two_levels_up,\n",
    "    f\"assume/examples/output/{EXAMPLE}/{EPISODES}_episodes_{SIM_TIMESPAN_DAYS}_simDays_{NUMBER_OF_AGENTS}_rlAgents\",\n",
    ")\n",
    "actor_path = os.path.join(path, f\"actor_pp_{ACTOR_NUM_ADJ}.pt\")\n",
    "\n",
    "# DEFINTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe95d9",
   "metadata": {
    "id": "ddfe95d9"
   },
   "source": [
    "We define a utility function to load observations and input data from a specified path. Analyzing the shap values for all observations and all parameters would make this notebook quite lengthy, so we’re filtering the observation data frame to include only 700 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44862f06",
   "metadata": {
    "id": "44862f06"
   },
   "outputs": [],
   "source": [
    "# @title Load observations function\n",
    "\n",
    "\n",
    "def load_observations(path, ACTOR_NUM, feature_names):\n",
    "    # Load observations\n",
    "    obs_path = f\"{path}/buffer_obs.json\"\n",
    "\n",
    "    with open(obs_path) as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # Convert the list of lists into a 2D numpy array\n",
    "    input_data = np.array(json_data)\n",
    "    input_data = np.squeeze(input_data)\n",
    "\n",
    "    # filter out arrays where all value are 0\n",
    "    input_data = input_data[~np.all(input_data == 0, axis=1)]\n",
    "\n",
    "    # filter only first 700 observations\n",
    "    input_data = input_data[:700]\n",
    "\n",
    "    if NUMBER_OF_AGENTS == 1:\n",
    "        return pd.DataFrame(input_data, columns=feature_names), input_data\n",
    "    else:\n",
    "        return pd.DataFrame(\n",
    "            input_data[:, ACTOR_NUM], columns=feature_names\n",
    "        ), input_data[:, ACTOR_NUM]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b8679",
   "metadata": {
    "id": "444b8679"
   },
   "source": [
    "**Define Paths and Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f218d15",
   "metadata": {
    "id": "7f218d15"
   },
   "source": [
    "Adjust the following paths and parameters according to your data and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa78b12",
   "metadata": {
    "id": "8fa78b12"
   },
   "outputs": [],
   "source": [
    "path = (\n",
    "    inputs_path + \"/example_02a/learned_strategies/base/buffer_obs\"\n",
    ")  # Replace with your data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9189ca",
   "metadata": {
    "id": "8f9189ca"
   },
   "outputs": [],
   "source": [
    "# Define feature names (replace with actual feature names)\n",
    "# make columns names\n",
    "names_1 = [\"price forecast t+\" + str(x) for x in range(1, 25)]\n",
    "names_2 = [\"residual load forecast t+\" + str(x) for x in range(1, 25)]\n",
    "feature_names = names_1 + names_2 + [\"total capacity t-1\"] + [\"marginal costs t-1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f1986",
   "metadata": {
    "id": "6c5f1986"
   },
   "source": [
    "**Load Observations and Input Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae8f9e",
   "metadata": {
    "id": "36ae8f9e"
   },
   "source": [
    "Load the observations and input data using the utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522969d",
   "metadata": {
    "id": "d522969d"
   },
   "outputs": [],
   "source": [
    "df_obs, input_data = load_observations(path, ACTOR_NUM, feature_names)\n",
    "\n",
    "df_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b9dcf",
   "metadata": {
    "id": "5d8b9dcf"
   },
   "source": [
    "**Load the Trained Actor Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b50488",
   "metadata": {
    "id": "b1b50488"
   },
   "source": [
    "We initialize and load the trained actor neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4de57",
   "metadata": {
    "id": "4da4de57"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "obs_dim = len(feature_names)\n",
    "act_dim = 2  # Adjust if your model outputs a different number of actions\n",
    "model = MLPActor(obs_dim=obs_dim, act_dim=act_dim, float_type=th.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37adecfa",
   "metadata": {
    "id": "37adecfa"
   },
   "outputs": [],
   "source": [
    "ACTOR_NUM = 1  # Replace with the actor number or identifier\n",
    "actor_path = (\n",
    "    inputs_path\n",
    "    + \"/example_02a/learned_strategies/base/last_policies/actors/actor_pp_6.pt\"\n",
    ")  # Path to the trained actor model\n",
    "\n",
    "# Load the trained model parameters\n",
    "model_state = th.load(actor_path, map_location=th.device(\"cpu\"))\n",
    "model.load_state_dict(model_state[\"actor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a63712",
   "metadata": {
    "id": "d4a63712"
   },
   "source": [
    "Get the actions base on observation tensor we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6460cfb",
   "metadata": {
    "id": "e6460cfb"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for obs in input_data:\n",
    "    obs_tensor = th.tensor(obs, dtype=th.float)\n",
    "    prediction = model(obs_tensor)\n",
    "    predictions.append(prediction)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91cd97",
   "metadata": {
    "id": "be91cd97",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_data, predictions, test_size=0.15, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c93c7",
   "metadata": {
    "id": "b21c93c7"
   },
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "y_train = th.stack(y_train)\n",
    "y_test = th.stack(y_test)\n",
    "\n",
    "X_train_tensor = th.tensor(X_train, dtype=th.float32)\n",
    "y_train_tensor = th.tensor(y_train, dtype=th.float32)\n",
    "X_test_tensor = th.tensor(X_test, dtype=th.float32)\n",
    "y_test_tensor = th.tensor(y_test, dtype=th.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1ab1e",
   "metadata": {
    "id": "ddd1ab1e"
   },
   "source": [
    "## 3.2. Creating a SHAP Explainer <a name=\"creating-a-shap-explainer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b108b",
   "metadata": {
    "id": "ae7b108b"
   },
   "source": [
    "We define a prediction function compatible with SHAP and create a Kernel SHAP explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9be211",
   "metadata": {
    "id": "6d9be211",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define a prediction function for SHAP\n",
    "def model_predict(X):\n",
    "    X_tensor = th.tensor(X, dtype=th.float32)\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        return model(X_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7857b",
   "metadata": {
    "id": "f0f7857b"
   },
   "outputs": [],
   "source": [
    "# Use a subset of training data for the background dataset\n",
    "background_size = 100  # Adjust the size as needed\n",
    "background = X_train[:background_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb96cf",
   "metadata": {
    "id": "84bb96cf"
   },
   "outputs": [],
   "source": [
    "# Create the SHAP Kernel Explainer\n",
    "explainer = shap.KernelExplainer(model_predict, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7929e4",
   "metadata": {
    "id": "2a7929e4"
   },
   "outputs": [],
   "source": [
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa277f",
   "metadata": {
    "id": "44fa277f"
   },
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3d550",
   "metadata": {
    "id": "c1f3d550"
   },
   "source": [
    "## 4. Visualizing SHAP Values <a name=\"visualizing-shap-values\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f0cbe",
   "metadata": {
    "id": "3a0f0cbe"
   },
   "source": [
    "We generate summary plots to visualize feature importance for each output dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af4983",
   "metadata": {
    "id": "a6af4983"
   },
   "outputs": [],
   "source": [
    "print(shap_values[0].shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e318a5b",
   "metadata": {
    "id": "2e318a5b"
   },
   "outputs": [],
   "source": [
    "# Summary plot for the first output dimension\n",
    "shap.summary_plot(shap_values[0], X_test, feature_names=feature_names, show=False)\n",
    "plt.title(\"Summary Plot for Output Dimension 0, p_inflex\")\n",
    "plt.show()\n",
    "\n",
    "# Summary plot for the second output dimension\n",
    "shap.summary_plot(shap_values[1], X_test, feature_names=feature_names, show=False)\n",
    "plt.title(\"Summary Plot for Output Dimension 1, p_flex\")\n",
    "plt.show()\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values[0],\n",
    "    X_test,\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    title=\"Summary Bar Plot for Output Dimension 0\",\n",
    ")\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values[1],\n",
    "    X_test,\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    title=\"Summary Bar Plot for Output Dimension 1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a888f8b",
   "metadata": {
    "id": "9a888f8b"
   },
   "source": [
    "The SHAP summary plots show the impact of each feature on the model's predictions for each output dimension (action). Features with larger absolute SHAP values have a more significant influence on the decision-making process of the RL agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4ce8c",
   "metadata": {
    "id": "c6c4ce8c"
   },
   "source": [
    "- **Positive SHAP Value**: Indicates that the feature contributes positively to the predicted action value.\n",
    "- **Negative SHAP Value**: Indicates that the feature contributes negatively to the predicted action value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86545200",
   "metadata": {
    "id": "86545200"
   },
   "source": [
    "By analyzing these plots, we can identify which features are most influential and understand how changes in feature values affect the agent's actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f3977c",
   "metadata": {
    "id": "06f3977c"
   },
   "source": [
    "## 5. Conclusion <a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd0a0c",
   "metadata": {
    "id": "dadd0a0c"
   },
   "source": [
    "In this tutorial, we've demonstrated how to apply SHAP to a reinforcement learning agent to explain its decision-making process. By interpreting the SHAP values, we gain valuable insights into which features influence the agent's actions, enhancing transparency and trust in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37633c16",
   "metadata": {
    "id": "37633c16"
   },
   "source": [
    "Explainability is crucial, especially when deploying RL agents in real-world applications where understanding the rationale behind decisions is essential for safety, fairness, and compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735d66f",
   "metadata": {
    "id": "8735d66f"
   },
   "source": [
    "## 6. Additional Resources <a name=\"additional-resources\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0332f",
   "metadata": {
    "id": "d6b0332f"
   },
   "source": [
    "- **SHAP Documentation**: [https://shap.readthedocs.io/en/latest/](https://shap.readthedocs.io/en/latest/)\n",
    "- **PyTorch Documentation**: [https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)\n",
    "- **Reinforcement Learning Introduction**: [Richard S. Sutton and Andrew G. Barto, \"Reinforcement Learning: An Introduction\"](http://incompleteideas.net/book/the-book-2nd.html)\n",
    "- **Interpretable Machine Learning Book**: [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cdea5f",
   "metadata": {
    "id": "a8cdea5f"
   },
   "source": [
    "**Feel free to experiment with the code and explore different explainability techniques. Happy learning!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
